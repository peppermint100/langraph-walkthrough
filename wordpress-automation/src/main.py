import asyncio
import os
from datetime import datetime
from typing import Dict, Any
from loguru import logger
from dotenv import load_dotenv

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models.state import BlogState, WorkflowStatus
from src.models.content_models import ContentType
from src.nodes.information_collection import information_collection_node
from src.nodes.blog_writing import blog_writing_node


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def create_workflow() -> StateGraph:
    """
    LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±

    Returns:
        êµ¬ì„±ëœ StateGraph ê°ì²´
    """

    # StateGraph ìƒì„±
    workflow = StateGraph(BlogState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("information_collection", information_collection_node)
    workflow.add_node("blog_writing", blog_writing_node)

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("information_collection")

    # ì—£ì§€ ì¶”ê°€ (ë…¸ë“œ ê°„ ì—°ê²°)
    workflow.add_edge("information_collection", "blog_writing")
    workflow.add_edge("blog_writing", END)

    # ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ (ìƒíƒœì— ë”°ë¥¸ ë¶„ê¸°)
    def should_continue_to_writing(state: BlogState) -> str:
        """ì •ë³´ ìˆ˜ì§‘ í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""
        if state.status == WorkflowStatus.FAILED:
            return END
        elif state.collected_content and state.collected_content.total_sources > 0:
            return "blog_writing"
        else:
            return END

    workflow.add_conditional_edges(
        "information_collection",
        should_continue_to_writing,
        {
            "blog_writing": "blog_writing",
            END: END
        }
    )

    def should_complete_workflow(state: BlogState) -> str:
        """ë¸”ë¡œê·¸ ì‘ì„± í›„ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì—¬ë¶€ ê²°ì •"""
        if state.status == WorkflowStatus.FAILED:
            return END
        elif state.generated_article:
            return END
        else:
            return END

    workflow.add_conditional_edges(
        "blog_writing",
        should_complete_workflow,
        {END: END}
    )

    return workflow


async def run_blog_automation(
    topic: str,
    target_audience: str = "ì¼ë°˜",
    tone: str = "ì¹œê·¼í•˜ê³  ì •ë³´ì„±",
    save_result: bool = True,
    output_dir: str = "./output"
) -> Dict[str, Any]:
    """
    ë¸”ë¡œê·¸ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Args:
        topic: ë¸”ë¡œê·¸ ì£¼ì œ
        target_audience: íƒ€ê²Ÿ ë…ìì¸µ
        tone: ê¸€ì˜ í†¤ì•¤ë§¤ë„ˆ
        save_result: ê²°ê³¼ íŒŒì¼ ì €ì¥ ì—¬ë¶€
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        ì‹¤í–‰ ê²°ê³¼
    """

    logger.info(f"ë¸”ë¡œê·¸ ìë™í™” ì‹œì‘: '{topic}'")

    try:
        # ì´ˆê¸° ìƒíƒœ ìƒì„±
        initial_state = BlogState(
            topic=topic,
            target_audience=target_audience,
            tone=tone,
            started_at=datetime.now().isoformat()
        )

        # ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ì»´íŒŒì¼
        workflow = create_workflow()
        checkpointer = MemorySaver()
        app = workflow.compile(checkpointer=checkpointer)

        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        config = {"configurable": {"thread_id": f"blog_{datetime.now().strftime('%Y%m%d_%H%M%S')}"}}

        logger.info("LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘")
        final_state = None

        async for output in app.astream(initial_state, config=config):
            for node_name, node_output in output.items():
                logger.info(f"ë…¸ë“œ '{node_name}' ì‹¤í–‰ ì™„ë£Œ")
                if isinstance(node_output, dict) and "status" in node_output:
                    logger.info(f"ìƒíƒœ: {node_output.get('status')}")

                # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
                if isinstance(node_output, BlogState):
                    final_state = node_output
                elif isinstance(node_output, dict):
                    # ë”•ì…”ë„ˆë¦¬ ì¶œë ¥ì„ ìƒíƒœì— ë°˜ì˜
                    if final_state is None:
                        final_state = initial_state
                    for key, value in node_output.items():
                        if hasattr(final_state, key):
                            setattr(final_state, key, value)

        # ìµœì¢… ìƒíƒœê°€ ì—†ìœ¼ë©´ ì´ˆê¸° ìƒíƒœ ì‚¬ìš©
        if final_state is None:
            final_state = initial_state
            final_state.set_status(WorkflowStatus.FAILED, "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨")

        # ì™„ë£Œ ì‹œê°„ ì„¤ì •
        if final_state.status != WorkflowStatus.FAILED:
            final_state.completed_at = datetime.now().isoformat()
            final_state.set_status(WorkflowStatus.COMPLETED, "ë¸”ë¡œê·¸ ìë™í™” ì™„ë£Œ")

        logger.info(f"ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: {final_state.status}")

        # ê²°ê³¼ ì €ì¥
        result_data = final_state.get_summary()
        if save_result and final_state.generated_article:
            save_path = await save_blog_result(final_state, output_dir)
            result_data["saved_file"] = save_path

        return {
            "success": final_state.status == WorkflowStatus.COMPLETED,
            "final_state": final_state,
            "summary": result_data
        }

    except Exception as e:
        error_msg = f"ë¸”ë¡œê·¸ ìë™í™” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        logger.error(error_msg)
        return {
            "success": False,
            "error": error_msg,
            "final_state": None
        }


async def save_blog_result(state: BlogState, output_dir: str) -> str:
    """
    ë¸”ë¡œê·¸ ìë™í™” ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥

    Args:
        state: ìµœì¢… ìƒíƒœ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """

    os.makedirs(output_dir, exist_ok=True)

    # íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_topic = "".join(c for c in state.topic if c.isalnum() or c in (' ', '-', '_')).strip()
    safe_topic = safe_topic.replace(' ', '_')[:50]
    filename = f"blog_{safe_topic}_{timestamp}.md"
    filepath = os.path.join(output_dir, filename)

    # ë§ˆí¬ë‹¤ìš´ ë‚´ìš© ìƒì„±
    markdown_content = f"""# {state.generated_article.title}

**ìƒì„± ì¼ì‹œ**: {state.completed_at}
**ì£¼ì œ**: {state.topic}
**íƒ€ê²Ÿ ë…ì**: {state.target_audience}
**í†¤ì•¤ë§¤ë„ˆ**: {state.tone}
**ì˜ˆìƒ ì½ê¸° ì‹œê°„**: {state.generated_article.estimated_read_time}ë¶„
**ë‹¨ì–´ ìˆ˜**: {state.generated_article.word_count}ì

---

## ë©”íƒ€ë°ì´í„°

- **ì¹´í…Œê³ ë¦¬**: {state.generated_article.category}
- **íƒœê·¸**: {', '.join(state.generated_article.meta_tags)}
- **í‚¤ì›Œë“œ**: {', '.join(state.generated_article.keywords)}

---

## ë³¸ë¬¸

{state.generated_article.content}

---

## ìƒì„± ì •ë³´

### ìˆ˜ì§‘ëœ ì†ŒìŠ¤
- **ì´ ì†ŒìŠ¤ ìˆ˜**: {state.collected_content.total_sources}
- **ê¸°ë³¸ ê°œë…**: {len(state.collected_content.basic_concepts)}ê°œ
- **ìµœì‹  íŠ¸ë Œë“œ**: {len(state.collected_content.latest_trends)}ê°œ
- **ì „ë¬¸ê°€ ì˜ê²¬**: {len(state.collected_content.expert_opinions)}ê°œ

### ì²˜ë¦¬ ë¡œê·¸
"""

    # ë¡œê·¸ ì¶”ê°€
    for log in state.logs:
        markdown_content += f"- {log}\n"

    # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if state.errors:
        markdown_content += "\n### ë°œìƒí•œ ì˜¤ë¥˜\n"
        for error in state.errors:
            markdown_content += f"- {error}\n"

    # íŒŒì¼ ì €ì¥
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(markdown_content)

    logger.info(f"ë¸”ë¡œê·¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    return filepath


def print_workflow_summary(result: Dict[str, Any]):
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""

    print("\n" + "="*60)
    print("ğŸ¤– WordPress ë¸”ë¡œê·¸ ìë™í™” ê²°ê³¼")
    print("="*60)

    if result["success"]:
        state = result["final_state"]
        summary = result["summary"]

        print(f"âœ… ìƒíƒœ: ì„±ê³µ")
        print(f"ğŸ“ ì£¼ì œ: {summary['topic']}")
        print(f"ğŸ“Š ì§„í–‰ë¥ : {summary['progress']}")
        print(f"ğŸ“„ ìƒì„±ëœ ê¸€: '{state.generated_article.title}'")
        print(f"ğŸ“ ë‹¨ì–´ ìˆ˜: {summary['word_count']}ì")
        print(f"â±ï¸  ì˜ˆìƒ ì½ê¸° ì‹œê°„: {state.generated_article.estimated_read_time}ë¶„")
        print(f"ğŸ” ìˆ˜ì§‘ëœ ì†ŒìŠ¤: {summary['sources_collected']}ê°œ")

        if "saved_file" in summary:
            print(f"ğŸ’¾ ì €ì¥ëœ íŒŒì¼: {summary['saved_file']}")

        print(f"ğŸ• ì‹œì‘: {summary['started_at']}")
        print(f"ğŸ• ì™„ë£Œ: {summary['completed_at']}")

    else:
        print(f"âŒ ìƒíƒœ: ì‹¤íŒ¨")
        print(f"ğŸš¨ ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

    print("="*60 + "\n")


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # ê¸°ë³¸ ì„¤ì •
    logger.add("logs/blog_automation_{time}.log", rotation="1 day")

    # ì˜ˆì œ ì‹¤í–‰
    topic = "ë§ˆí¬êµ¬ í•œì˜ì›"

    print(f"ğŸš€ ë¸”ë¡œê·¸ ìë™í™” ì‹œì‘: '{topic}'")
    print("Processing... (ëª‡ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n")

    result = await run_blog_automation(
        topic=topic,
        target_audience="ì¼ë°˜ì¸",
        tone="ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´",
        save_result=True,
        output_dir="./output"
    )

    print_workflow_summary(result)


if __name__ == "__main__":
    asyncio.run(main())